<html>
<head>
    <title>sampling_from_vs2.ipynb</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <style type="text/css">
        .s0 {
            color: #808080;
        }

        .s1 {
            color: #a9b7c6;
        }

        .s2 {
            color: #cc7832;
        }

        .s3 {
            color: #6897bb;
        }

        .s4 {
            color: #6a8759;
        }

        .ln {
            color: #606366;
            font-weight: normal;
            font-style: normal;
        }
    </style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060">
    <tr>
        <td>
            <center>
                <font face="Arial, Helvetica" color="#000000">
                    sampling_from_vs2.ipynb</font>
            </center>
        </td>
    </tr>
</table>
<pre><a name="l1"><span class="ln">1    </span></a><span class="s0">#%% md 
<a name="l2"><span class="ln">2    </span></a></span><span class="s1"># Sampling from the version space 
<a name="l3"><span class="ln">3    </span></a> 
<a name="l4"><span class="ln">4    </span></a>Let's consider a simple example where we have access to the true rules that generated the data. We can build a dataset that is generated by these rules and then build the version space, that is, a set of all possible rules that could have generated the data. We can then sample from this version space with different techniques and see how classification performance changes. 
<a name="l5"><span class="ln">5    </span></a> 
<a name="l6"><span class="ln">6    </span></a>We consider the following ground truth rule set (i.e., a DNF). 
<a name="l7"><span class="ln">7    </span></a> 
<a name="l8"><span class="ln">8    </span></a>$$x_0=0 \wedge x_1=1 \vee x_2=1$$ 
<a name="l9"><span class="ln">9    </span></a> 
<a name="l10"><span class="ln">10   </span></a>We consider as hypothesis space the set of m-terms k-DNF, that is, all possible combinations **up to** $k$ different conjunctive rules put in OR, where each rule is a conjunction of **at most** $m$ features. 
<a name="l11"><span class="ln">11   </span></a> 
<a name="l12"><span class="ln">12   </span></a>For example, the chosen DNF is a 2-term 2-DNF. Instead, a 3-term 2-DNF could be $x_0=0 \wedge x_1=1 \wedge x_3=1 \vee x_2=1$. 
<a name="l13"><span class="ln">13   </span></a> 
<a name="l14"><span class="ln">14   </span></a>The hypothesis space chosen is a 3-term 3-DNF. This means that we can have rules like $x_0=0 \wedge x_1=1 \wedge x_3=1 \vee x_2=1 \vee x_4=0$. While it may seem like it's small, it's actually quite big. For 8 features, we have 31,850,976 possible DNFs. 
<a name="l15"><span class="ln">15   </span></a></span><span class="s0">#%% 
<a name="l16"><span class="ln">16   </span></a></span><span class="s2">import </span><span class="s1">math</span>
<a name="l17"><span class="ln">17   </span></a>
<a name="l18"><span class="ln">18   </span></a><span class="s2">from </span><span class="s1">tqdm </span><span
            class="s2">import </span><span class="s1">tqdm</span>
<a name="l19"><span class="ln">19   </span></a>
<a name="l20"><span class="ln">20   </span></a><span class="s2">from </span><span class="s1">bpllib.rules._discrete_constraint </span><span
            class="s2">import </span><span class="s1">DiscreteConstraint</span>
<a name="l21"><span class="ln">21   </span></a><span class="s2">from </span><span
            class="s1">bpllib.rules._rule </span><span class="s2">import </span><span class="s1">Rule</span>
<a name="l22"><span class="ln">22   </span></a><span class="s2">import </span><span class="s1">numpy </span><span
            class="s2">as </span><span class="s1">np</span>
<a name="l23"><span class="ln">23   </span></a><span class="s2">import </span><span class="s1">pandas </span><span
            class="s2">as </span><span class="s1">pd</span>
<a name="l24"><span class="ln">24   </span></a><span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span
            class="s2">as </span><span class="s1">plt</span>
<a name="l25"><span class="ln">25   </span></a>
<a name="l26"><span class="ln">26   </span></a><span class="s0"># random rules</span>
<a name="l27"><span class="ln">27   </span></a><span class="s1">r1 = Rule(constraints={</span><span
            class="s3">0</span><span class="s1">: DiscreteConstraint(value=</span><span class="s3">0</span><span
            class="s2">, </span><span class="s1">index=</span><span class="s3">0</span><span class="s1">)</span><span
            class="s2">,</span>
<a name="l28"><span class="ln">28   </span></a>                       <span class="s3">1</span><span class="s1">: DiscreteConstraint(value=</span><span
            class="s3">1</span><span class="s2">, </span><span class="s1">index=</span><span class="s3">1</span><span
            class="s1">)</span><span class="s2">,</span>
<a name="l29"><span class="ln">29   </span></a>                       <span class="s0">#3: DiscreteConstraint(value=0, index=3)</span>
<a name="l30"><span class="ln">30   </span></a>                       <span class="s1">})</span>
<a name="l31"><span class="ln">31   </span></a>
<a name="l32"><span class="ln">32   </span></a><span class="s1">r2 = Rule(constraints={</span><span
            class="s3">2</span><span class="s1">: DiscreteConstraint(value=</span><span class="s3">1</span><span
            class="s2">, </span><span class="s1">index=</span><span class="s3">2</span><span class="s1">)</span><span
            class="s2">,</span>
<a name="l33"><span class="ln">33   </span></a>                       <span class="s0">#4: DiscreteConstraint(value=1, index=4)</span>
<a name="l34"><span class="ln">34   </span></a>                       <span class="s1">}</span>
<a name="l35"><span class="ln">35   </span></a>          <span class="s1">)</span>
<a name="l36"><span class="ln">36   </span></a>
<a name="l37"><span class="ln">37   </span></a><span class="s0"># r3 = Rule(constraints={5: DiscreteConstraint(value=1, index=5),</span>
<a name="l38"><span class="ln">38   </span></a><span class="s0">#                       6: DiscreteConstraint(value=0, index=6)})</span>
<a name="l39"><span class="ln">39   </span></a>
<a name="l40"><span class="ln">40   </span></a><span class="s1">rule_set = [r1</span><span class="s2">, </span><span
            class="s1">r2]</span>
<a name="l41"><span class="ln">41   </span></a>
<a name="l42"><span class="ln">42   </span></a><span class="s0">#%% md 
<a name="l43"><span class="ln">43   </span></a></span><span class="s1">## Generate data 
<a name="l44"><span class="ln">44   </span></a> 
<a name="l45"><span class="ln">45   </span></a>We generate a dataset of 100 samples for the train set and the test set. We use the same rules to generate the labels for both sets. 
<a name="l46"><span class="ln">46   </span></a> 
<a name="l47"><span class="ln">47   </span></a>Each datapoint is in $\{0, 1\}^8$. The rules involve only the first three features, hence rules in the version space may have spurious features inside. 
<a name="l48"><span class="ln">48   </span></a> 
<a name="l49"><span class="ln">49   </span></a>All the possible conjunctive rules involving 8 features and 3 terms are 576. IDEA TO IMPLEMENT: we can already filter out the ones that cover any negative example. Of course, they will not be in the version space. We can't remove rules that don't cover any positive example, because they can still be in the version space. 
<a name="l50"><span class="ln">50   </span></a></span><span class="s0">#%% 
<a name="l51"><span class="ln">51   </span></a></span><span class="s1">X_train = np.random.randint(</span><span
            class="s3">0</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span
            class="s1">size=(</span><span class="s3">100</span><span class="s2">, </span><span class="s3">8</span><span
            class="s1">))</span>
<a name="l52"><span class="ln">52   </span></a><span class="s1">y_train = np.array([any([r.covers(x) </span><span
            class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span
            class="s1">rule_set]) </span><span class="s2">for </span><span class="s1">x </span><span
            class="s2">in </span><span class="s1">X_train])</span>
<a name="l53"><span class="ln">53   </span></a><span class="s1">X_test = np.random.randint(</span><span
            class="s3">0</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span
            class="s1">size=(</span><span class="s3">100</span><span class="s2">, </span><span class="s3">8</span><span
            class="s1">))</span>
<a name="l54"><span class="ln">54   </span></a><span class="s1">y_test = np.array([any([r.covers(x) </span><span
            class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span
            class="s1">rule_set]) </span><span class="s2">for </span><span class="s1">x </span><span
            class="s2">in </span><span class="s1">X_test])</span>
<a name="l55"><span class="ln">55   </span></a>
<a name="l56"><span class="ln">56   </span></a><span class="s1">y_train.sum()</span>
<a name="l57"><span class="ln">57   </span></a>
<a name="l58"><span class="ln">58   </span></a><span class="s2">import </span><span class="s1">itertools</span>
<a name="l59"><span class="ln">59   </span></a>
<a name="l60"><span class="ln">60   </span></a>
<a name="l61"><span class="ln">61   </span></a><span class="s2">def </span><span class="s1">generate_rules(m</span><span
            class="s2">, </span><span class="s1">n_features=</span><span class="s3">7</span><span class="s1">):</span>
<a name="l62"><span class="ln">62   </span></a>    <span class="s1">all_features = list(range(n_features))</span>
<a name="l63"><span class="ln">63   </span></a>    <span
            class="s1">combos = itertools.combinations(all_features</span><span class="s2">, </span><span
            class="s1">m)</span>
<a name="l64"><span class="ln">64   </span></a>    <span class="s1">rules = set()</span>
<a name="l65"><span class="ln">65   </span></a>    <span class="s2">for </span><span class="s1">combo </span><span
            class="s2">in </span><span class="s1">combos:</span>
<a name="l66"><span class="ln">66   </span></a>        <span class="s2">for </span><span class="s1">combo_values </span><span
            class="s2">in </span><span class="s1">itertools.product([</span><span class="s3">0</span><span
            class="s2">, </span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span
            class="s1">repeat=m):</span>
<a name="l67"><span class="ln">67   </span></a>            <span class="s1">rule = Rule(constraints={})</span>
<a name="l68"><span class="ln">68   </span></a>            <span class="s2">for </span><span class="s1">i </span><span
            class="s2">in </span><span class="s1">range(m):</span>
<a name="l69"><span class="ln">69   </span></a>                <span class="s2">if </span><span class="s1">combo_values[i] == </span><span
            class="s3">0</span><span class="s1">:</span>
<a name="l70"><span class="ln">70   </span></a>                    <span class="s1">rule.constraints[combo[i]] = DiscreteConstraint(value=</span><span
            class="s3">0</span><span class="s2">, </span><span class="s1">index=combo[i])</span>
<a name="l71"><span class="ln">71   </span></a>                <span class="s2">else</span><span class="s1">:</span>
<a name="l72"><span class="ln">72   </span></a>                    <span class="s1">rule.constraints[combo[i]] = DiscreteConstraint(value=</span><span
            class="s3">1</span><span class="s2">, </span><span class="s1">index=combo[i])</span>
<a name="l73"><span class="ln">73   </span></a>            <span class="s1">rules.add(rule)</span>
<a name="l74"><span class="ln">74   </span></a>    <span class="s2">return </span><span class="s1">rules</span>
<a name="l75"><span class="ln">75   </span></a>
<a name="l76"><span class="ln">76   </span></a>
<a name="l77"><span class="ln">77   </span></a><span class="s1">rules_space = set.union(*[generate_rules(m=m</span><span
            class="s2">, </span><span class="s1">n_features=</span><span class="s3">8</span><span
            class="s1">) </span><span class="s2">for </span><span class="s1">m </span><span class="s2">in </span><span
            class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">4</span><span
            class="s1">)])</span>
<a name="l78"><span class="ln">78   </span></a><span class="s1">print(len(rules_space))</span>
<a name="l79"><span class="ln">79   </span></a>
<a name="l80"><span class="ln">80   </span></a>
<a name="l81"><span class="ln">81   </span></a><span class="s0">#%% 
<a name="l82"><span class="ln">82   </span></a></span><span class="s2">def </span><span class="s1">generate_tuples_async(k):</span>
<a name="l83"><span class="ln">83   </span></a>    <span class="s2">for </span><span class="s1">i </span><span
            class="s2">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span
            class="s1">k + </span><span class="s3">1</span><span class="s1">):</span>
<a name="l84"><span class="ln">84   </span></a>        <span
            class="s1">tuples = itertools.combinations(rules_space</span><span class="s2">, </span><span
            class="s1">i)</span>
<a name="l85"><span class="ln">85   </span></a>
<a name="l86"><span class="ln">86   </span></a>        <span class="s2">for </span><span class="s1">t </span><span
            class="s2">in </span><span class="s1">tuples:</span>
<a name="l87"><span class="ln">87   </span></a>            <span class="s2">yield </span><span class="s1">t</span>
<a name="l88"><span class="ln">88   </span></a><span class="s0">#%% 
<a name="l89"><span class="ln">89   </span></a># takes 5 minutes</span>
<a name="l90"><span class="ln">90   </span></a>
<a name="l91"><span class="ln">91   </span></a><span class="s1">VS = set()</span>
<a name="l92"><span class="ln">92   </span></a>
<a name="l93"><span class="ln">93   </span></a><span class="s2">from </span><span class="s1">tqdm </span><span
            class="s2">import </span><span class="s1">tqdm</span>
<a name="l94"><span class="ln">94   </span></a><span class="s2">for </span><span class="s1">h </span><span
            class="s2">in </span><span class="s1">tqdm(generate_tuples_async(</span><span class="s3">3</span><span
            class="s1">)</span><span class="s2">, </span><span class="s1">total=math.comb(len(rules_space)</span><span
            class="s2">, </span><span class="s3">3</span><span class="s1">)):</span>
<a name="l95"><span class="ln">95   </span></a>    <span class="s1">ok = </span><span class="s2">True</span>
<a name="l96"><span class="ln">96   </span></a>    <span class="s2">for </span><span class="s1">x </span><span
            class="s2">in </span><span class="s1">X_train[y_train==</span><span class="s3">1</span><span
            class="s1">]:</span>
<a name="l97"><span class="ln">97   </span></a>        <span class="s2">if not </span><span
            class="s1">any([r.covers(x) </span><span class="s2">for </span><span class="s1">r </span><span
            class="s2">in </span><span class="s1">h]):</span>
<a name="l98"><span class="ln">98   </span></a>            <span class="s1">ok = </span><span class="s2">False</span>
<a name="l99"><span class="ln">99   </span></a>            <span class="s2">break</span>
<a name="l100"><span class="ln">100  </span></a>    <span class="s2">for </span><span class="s1">x </span><span
            class="s2">in </span><span class="s1">X_train[y_train==</span><span class="s3">0</span><span
            class="s1">]:</span>
<a name="l101"><span class="ln">101  </span></a>        <span class="s2">if </span><span
            class="s1">any([r.covers(x) </span><span class="s2">for </span><span class="s1">r </span><span
            class="s2">in </span><span class="s1">h]):</span>
<a name="l102"><span class="ln">102  </span></a>            <span class="s1">ok = </span><span class="s2">False</span>
<a name="l103"><span class="ln">103  </span></a>            <span class="s2">break</span>
<a name="l104"><span class="ln">104  </span></a>    <span class="s2">if </span><span class="s1">ok:</span>
<a name="l105"><span class="ln">105  </span></a>        <span class="s1">VS.add(h)</span>
<a name="l106"><span class="ln">106  </span></a><span class="s0">#%% 
<a name="l107"><span class="ln">107  </span></a></span><span class="s1">len(VS)  </span><span
            class="s0"># should be 246</span>
<a name="l108"><span class="ln">108  </span></a><span class="s0">#%% md 
<a name="l109"><span class="ln">109  </span></a></span><span class="s1">Here we can see the rules found. The shortest rule is the correct one (the one that generated the data), 
<a name="l110"><span class="ln">110  </span></a> 
<a name="l111"><span class="ln">111  </span></a>(X[2] == 1, X[0] == 0 ^ X[1] == 1) 
<a name="l112"><span class="ln">112  </span></a> 
<a name="l113"><span class="ln">113  </span></a>But we can also find many other different, valid DNFs. 
<a name="l114"><span class="ln">114  </span></a></span><span class="s0">#%% 
<a name="l115"><span class="ln">115  </span></a></span><span class="s1">sorted(VS</span><span class="s2">, </span><span
            class="s1">key=len)</span>
<a name="l116"><span class="ln">116  </span></a><span class="s0">#%% md 
<a name="l117"><span class="ln">117  </span></a></span><span class="s1">## Uniform and weighted sampling 
<a name="l118"><span class="ln">118  </span></a> 
<a name="l119"><span class="ln">119  </span></a>Here we implement the uniform sampling from the version space. We also implement the weighted sampling, where the probability of a ruleset is proportional to the length of the ruleset, i.e., the number of ORs. 
<a name="l120"><span class="ln">120  </span></a> 
<a name="l121"><span class="ln">121  </span></a>To estimate correctly the performance of the sampling, we repeat the sampling 10000 times and compute the mean and the standard deviation of the accuracy on the test dataset. 
<a name="l122"><span class="ln">122  </span></a></span><span class="s0">#%% 
<a name="l123"><span class="ln">123  </span></a></span><span class="s2">import </span><span class="s1">random</span>
<a name="l124"><span class="ln">124  </span></a><span class="s2">from </span><span
            class="s1">sklearn.metrics </span><span class="s2">import </span><span class="s1">accuracy_score</span>
<a name="l125"><span class="ln">125  </span></a>
<a name="l126"><span class="ln">126  </span></a><span class="s2">def </span><span class="s1">uniform_bp(T=</span><span
            class="s3">3</span><span class="s2">, </span><span class="s1">iters=</span><span
            class="s3">10000</span><span class="s2">, </span><span class="s1">return_sample=</span><span class="s2">False</span><span
            class="s1">):</span>
<a name="l127"><span class="ln">127  </span></a>    <span class="s1">accuracies = []</span>
<a name="l128"><span class="ln">128  </span></a>    <span class="s2">for </span><span class="s1">i </span><span
            class="s2">in </span><span class="s1">range(iters):</span>
<a name="l129"><span class="ln">129  </span></a>        <span class="s0"># sample from VS</span>
<a name="l130"><span class="ln">130  </span></a>        <span class="s1">uniform_sample = random.choices(list(VS)</span><span
            class="s2">, </span><span class="s1">k=T)</span>
<a name="l131"><span class="ln">131  </span></a>        <span
            class="s1">y_pred = np.array([sum([any([r.covers(x) </span><span class="s2">for </span><span
            class="s1">r </span><span class="s2">in </span><span class="s1">h]) </span><span class="s2">for </span><span
            class="s1">h </span><span class="s2">in </span><span class="s1">uniform_sample]) &gt;= T // </span><span
            class="s3">2 </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span
            class="s1">X_test])</span>
<a name="l132"><span class="ln">132  </span></a>
<a name="l133"><span class="ln">133  </span></a>        <span class="s1">acc = accuracy_score(y_pred</span><span
            class="s2">, </span><span class="s1">y_test)</span>
<a name="l134"><span class="ln">134  </span></a>        <span class="s1">accuracies.append(acc)</span>
<a name="l135"><span class="ln">135  </span></a>    <span class="s1">print(</span><span class="s4">&quot;(beta={}, unif) {} +- {} (N={})&quot;</span><span
            class="s1">.format(</span><span class="s3">0</span><span class="s2">, </span><span class="s1">np.mean(accuracies)</span><span
            class="s2">, </span><span class="s1">np.std(accuracies)</span><span class="s2">, </span><span class="s1">iters))</span>
<a name="l136"><span class="ln">136  </span></a>    <span class="s2">if </span><span class="s1">return_sample:</span>
<a name="l137"><span class="ln">137  </span></a>        <span class="s2">return </span><span
            class="s1">uniform_sample</span>
<a name="l138"><span class="ln">138  </span></a>    <span class="s2">return </span><span
            class="s1">np.mean(accuracies)</span><span class="s2">, </span><span class="s1">np.std(accuracies)</span>
<a name="l139"><span class="ln">139  </span></a><span class="s0">#%% 
<a name="l140"><span class="ln">140  </span></a></span><span class="s2">def </span><span
            class="s1">weighted_bp(T=</span><span class="s3">3</span><span class="s2">, </span><span
            class="s1">beta=</span><span class="s3">10</span><span class="s2">, </span><span
            class="s1">iters=</span><span class="s3">10000</span><span class="s2">, </span><span class="s1">return_sample=</span><span
            class="s2">False</span><span class="s1">):</span>
<a name="l141"><span class="ln">141  </span></a>    <span class="s1">accuracies = []</span>
<a name="l142"><span class="ln">142  </span></a>    <span class="s2">for </span><span class="s1">i </span><span
            class="s2">in </span><span class="s1">range(iters):</span>
<a name="l143"><span class="ln">143  </span></a>        <span
            class="s1">p = np.array([np.exp(-beta * len(h)) </span><span class="s2">for </span><span
            class="s1">h </span><span class="s2">in </span><span class="s1">VS])</span>
<a name="l144"><span class="ln">144  </span></a>        <span class="s1">p = p / sum(p)</span>
<a name="l145"><span class="ln">145  </span></a>        <span
            class="s1">weighted_sample = random.choices(list(VS)</span><span class="s2">, </span><span
            class="s1">k=T</span><span class="s2">, </span><span class="s1">weights=p)</span>
<a name="l146"><span class="ln">146  </span></a>        <span
            class="s1">y_pred = np.array([sum([any([r.covers(x) </span><span class="s2">for </span><span
            class="s1">r </span><span class="s2">in </span><span class="s1">h]) </span><span class="s2">for </span><span
            class="s1">h </span><span class="s2">in </span><span class="s1">weighted_sample]) &gt;= T // </span><span
            class="s3">2 </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span
            class="s1">X_test])</span>
<a name="l147"><span class="ln">147  </span></a>
<a name="l148"><span class="ln">148  </span></a>        <span class="s1">acc = accuracy_score(y_pred</span><span
            class="s2">, </span><span class="s1">y_test)</span>
<a name="l149"><span class="ln">149  </span></a>        <span class="s1">accuracies.append(acc)</span>
<a name="l150"><span class="ln">150  </span></a>    <span class="s1">print(</span><span class="s4">&quot;(beta={}) {} +- {} (N={})&quot;</span><span
            class="s1">.format(beta</span><span class="s2">, </span><span class="s1">np.mean(accuracies)</span><span
            class="s2">, </span><span class="s1">np.std(accuracies)</span><span class="s2">, </span><span class="s1">iters))</span>
<a name="l151"><span class="ln">151  </span></a>    <span class="s2">if </span><span class="s1">return_sample:</span>
<a name="l152"><span class="ln">152  </span></a>        <span class="s2">return </span><span
            class="s1">weighted_sample</span>
<a name="l153"><span class="ln">153  </span></a>    <span class="s2">return </span><span
            class="s1">np.mean(accuracies)</span><span class="s2">, </span><span class="s1">np.std(accuracies)</span>
<a name="l154"><span class="ln">154  </span></a><span class="s0">#%% md 
<a name="l155"><span class="ln">155  </span></a></span><span class="s1">Using uniform sampling, we can see many spurious rules. 
<a name="l156"><span class="ln">156  </span></a></span><span class="s0">#%% 
<a name="l157"><span class="ln">157  </span></a></span><span class="s1">uniform_bp(T=</span><span
            class="s3">3</span><span class="s2">, </span><span class="s1">return_sample=</span><span
            class="s2">True</span><span class="s1">)</span>
<a name="l158"><span class="ln">158  </span></a><span class="s0">#%% md 
<a name="l159"><span class="ln">159  </span></a></span><span class="s1">Using weighted sampling, we get a much better result. 
<a name="l160"><span class="ln">160  </span></a></span><span class="s0">#%% 
<a name="l161"><span class="ln">161  </span></a></span><span class="s1">weighted_bp(T=</span><span
            class="s3">3</span><span class="s2">, </span><span class="s1">return_sample=</span><span
            class="s2">True</span><span class="s1">)</span>
<a name="l162"><span class="ln">162  </span></a><span class="s0">#%% md 
<a name="l163"><span class="ln">163  </span></a></span><span class="s1">The results confirm our hypothesis. Using the uniform sampling we already get really good results, but they are further improved by using the weighted sampling. 
<a name="l164"><span class="ln">164  </span></a></span><span class="s0">#%% 
<a name="l165"><span class="ln">165  </span></a># create a plot with std error bars</span>
<a name="l166"><span class="ln">166  </span></a>
<a name="l167"><span class="ln">167  </span></a><span class="s2">import </span><span
            class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<a name="l168"><span class="ln">168  </span></a>
<a name="l169"><span class="ln">169  </span></a><span class="s2">def </span><span class="s1">plot_results(results</span><span
            class="s2">, </span><span class="s1">title):</span>
<a name="l170"><span class="ln">170  </span></a>    <span class="s1">means = [r[</span><span class="s3">0</span><span
            class="s1">] </span><span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span
            class="s1">results]</span>
<a name="l171"><span class="ln">171  </span></a>    <span class="s1">stds = [r[</span><span class="s3">1</span><span
            class="s1">] </span><span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span
            class="s1">results]</span>
<a name="l172"><span class="ln">172  </span></a>    <span class="s1">plt.errorbar(range(</span><span class="s3">1</span><span
            class="s2">, </span><span class="s1">len(means) + </span><span class="s3">1</span><span
            class="s1">)</span><span class="s2">, </span><span class="s1">np.array(means)</span><span
            class="s2">, </span><span class="s1">yerr=stds</span><span class="s2">, </span><span
            class="s1">fmt=</span><span class="s4">'o'</span><span class="s2">, </span><span
            class="s1">label=title)</span>
<a name="l173"><span class="ln">173  </span></a>
<a name="l174"><span class="ln">174  </span></a><span class="s0"># set y scale to log</span>
<a name="l175"><span class="ln">175  </span></a><span class="s0"># plt.yscale('log')</span>
<a name="l176"><span class="ln">176  </span></a><span class="s1">plot_results([uniform_bp(t</span><span
            class="s2">, </span><span class="s1">iters=</span><span class="s3">1000</span><span
            class="s1">) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span
            class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">6</span><span
            class="s1">)]</span><span class="s2">, </span><span class="s4">&quot;Uniform BP&quot;</span><span
            class="s1">)</span>
<a name="l177"><span class="ln">177  </span></a><span class="s1">plot_results([weighted_bp(t</span><span
            class="s2">, </span><span class="s1">iters=</span><span class="s3">1000</span><span
            class="s1">) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span
            class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">6</span><span
            class="s1">)]</span><span class="s2">, </span><span class="s4">&quot;Weighted BP&quot;</span><span
            class="s1">)</span>
<a name="l178"><span class="ln">178  </span></a><span class="s1">plt.title(</span><span
            class="s4">'comparison'</span><span class="s1">)</span>
<a name="l179"><span class="ln">179  </span></a><span class="s1">plt.xlabel(</span><span class="s4">&quot;T&quot;</span><span
            class="s1">)</span>
<a name="l180"><span class="ln">180  </span></a><span class="s1">plt.ylabel(</span><span
            class="s4">&quot;Accuracy&quot;</span><span class="s1">)</span>
<a name="l181"><span class="ln">181  </span></a><span class="s1">plt.legend()</span>
<a name="l182"><span class="ln">182  </span></a><span class="s1">plt.show()</span>
<a name="l183"><span class="ln">183  </span></a>
<a name="l184"><span class="ln">184  </span></a><span class="s0">#%% 
<a name="l185"><span class="ln">185  </span></a></span></pre>
</body>
</html>